# Advanced Bayesian Optimization for Hyperparameter Tuning of Deep Neural Networks

This project implements **Bayesian Optimization (BO)** to tune the hyperparameters of a moderately complex deep neural network (CNN) using the **Expected Improvement (EI)** acquisition function.  
The goal is to efficiently discover near-optimal learning rate, number of filters, batch size, and dense layer sizeâ€”using far fewer trials than random search or grid search.

Bayesian Optimization is applied on top of a baseline CNN trained on a synthetic multi-class dataset (CIFAR-like).  
All results, logs, and BO traces are included in this repository.

---

## ðŸš€ Project Structure

advanced-bo-hpo/
â”‚â”€â”€ README.md â†’ Main project documentation
â”‚â”€â”€ bayesian_opt.py â†’ BO driver script
â”‚â”€â”€ multiclass_cnn_baseline.py â†’ Baseline CNN model
â”‚â”€â”€ best_model_baseline.pth â†’ Saved best CNN model
â”‚â”€â”€ bo_results.csv â†’ All BO iterations + hyperparameters
â”‚â”€â”€ validation_scores.csv â†’ Baseline model validation metrics
â”‚â”€â”€ optimization_trace.txt â†’ BO optimization trace log
â”‚â”€â”€ search_space.json â†’ Hyperparameter definitions



---

## ðŸ“Œ 1. Baseline CNN Model

The baseline CNN (in `multiclass_cnn_baseline.py`):

- 3 convolutional layers  
- ReLU activations  
- MaxPooling  
- Flatten + Dense layers  
- Softmax classification  
- Trained for a small number of epochs to simulate expensive objective evaluation  

Output file:
best_model_baseline.pth


---

## ðŸ“Œ 2. Bayesian Optimization Pipeline

BO is implemented using:
- **scikit-optimize (`skopt`)**
- **Gaussian Process surrogate model**
- **Expected Improvement (EI)** acquisition function

Script:


bayesian_opt.py


Each BO iteration:
1. Samples candidate hyperparameters  
2. Trains the CNN for a fixed number of epochs  
3. Evaluates validation accuracy  
4. Updates Gaussian Process  
5. Writes logs + results

Outputs:


bo_results.csv â†’ all hyperparameters + accuracy
optimization_trace.txt â†’ BO sequence log
search_space.json â†’ hyperparameter definitions


---

## ðŸŽ¯ Hyperparameters Tuned

| Hyperparameter | Range |
|----------------|-------|
| Learning rate  | 1e-5 â†’ 1e-2 |
| Batch size     | 16 â†’ 128 |
| CNN Filters    | 16 â†’ 64 |
| Dense Units    | 64 â†’ 256 |

---

## ðŸ“Š Sample Results

### **Baseline Performance**
Loaded from `validation_scores.csv`:

| Metric | Value |
|--------|-------|
| Accuracy | ~0.70 |
| Loss | ~1.05 |

### **After Bayesian Optimization**
Best row in `bo_results.csv`:

| Hyperparameters | Best Accuracy |
|------------------|--------------|
| lr=0.0008, filters=48, dense=128, batch=64 | ~0.82 |

**Improvement: +12% accuracy**

---

## ðŸ§  Why Bayesian Optimization?

Unlike grid/random search, BO:

- Handles expensive models  
- Learns from previous trials  
- Narrows search efficiently  
- Uses Gaussian Processes to model objective  
- Maximizes Expected Improvement (EI)  

This results in **faster convergence and better accuracy**.

---

## ðŸ“¥ How to Run

### **Install Requirements**
```bash
pip install torch torchvision scikit-optimize numpy pandas

1. Train Baseline
python multiclass_cnn_baseline.py

2. Run Bayesian Optimization
python bayesian_opt.py

Conclusion

This project demonstrates:

âœ” Implementation of a deep CNN
âœ” Complete Bayesian Optimization loop
âœ” Analysis of acquisition function (EI)
âœ” Comparison vs baseline
âœ” Final optimized hyperparameters and improved performance
